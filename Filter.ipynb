{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sen</th>\n",
       "      <th>jens</th>\n",
       "      <th>dard ghafase sineh</th>\n",
       "      <th>feshar khun dar halat esterahat</th>\n",
       "      <th>kolestrol</th>\n",
       "      <th>ghand khun nashta</th>\n",
       "      <th>navar ghalb dar halat esterahat</th>\n",
       "      <th>hadaksar zaraban ghalb</th>\n",
       "      <th>anjin sadri nashi az varzesh</th>\n",
       "      <th>afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat</th>\n",
       "      <th>shibe tamrin dar oje tamrin dar maghtae ST</th>\n",
       "      <th>tedad oroghe bozorg rangi ba flourosopy</th>\n",
       "      <th>talasemi</th>\n",
       "      <th>ehtemal voghu bimari ghalbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sen  jens  dard ghafase sineh  feshar khun dar halat esterahat  kolestrol  \\\n",
       "0   63     1                   1                              145        233   \n",
       "1   67     1                   4                              160        286   \n",
       "2   67     1                   4                              120        229   \n",
       "3   37     1                   3                              130        250   \n",
       "4   41     0                   2                              130        204   \n",
       "\n",
       "   ghand khun nashta  navar ghalb dar halat esterahat  hadaksar zaraban ghalb  \\\n",
       "0                  1                                2                     150   \n",
       "1                  0                                2                     108   \n",
       "2                  0                                2                     129   \n",
       "3                  0                                0                     187   \n",
       "4                  0                                2                     172   \n",
       "\n",
       "   anjin sadri nashi az varzesh  \\\n",
       "0                             0   \n",
       "1                             1   \n",
       "2                             1   \n",
       "3                             0   \n",
       "4                             0   \n",
       "\n",
       "   afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat  \\\n",
       "0                                                2.3                   \n",
       "1                                                1.5                   \n",
       "2                                                2.6                   \n",
       "3                                                3.5                   \n",
       "4                                                1.4                   \n",
       "\n",
       "   shibe tamrin dar oje tamrin dar maghtae ST  \\\n",
       "0                                           3   \n",
       "1                                           2   \n",
       "2                                           2   \n",
       "3                                           3   \n",
       "4                                           1   \n",
       "\n",
       "    tedad oroghe bozorg rangi ba flourosopy  talasemi  \\\n",
       "0                                         0         6   \n",
       "1                                         3         3   \n",
       "2                                         2         7   \n",
       "3                                         0         3   \n",
       "4                                         0         3   \n",
       "\n",
       "   ehtemal voghu bimari ghalbi  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "Health=pd.read_excel('Health.xlsx')\n",
    "Health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sen</th>\n",
       "      <th>jens</th>\n",
       "      <th>dard ghafase sineh</th>\n",
       "      <th>feshar khun dar halat esterahat</th>\n",
       "      <th>kolestrol</th>\n",
       "      <th>ghand khun nashta</th>\n",
       "      <th>navar ghalb dar halat esterahat</th>\n",
       "      <th>hadaksar zaraban ghalb</th>\n",
       "      <th>anjin sadri nashi az varzesh</th>\n",
       "      <th>afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat</th>\n",
       "      <th>shibe tamrin dar oje tamrin dar maghtae ST</th>\n",
       "      <th>tedad oroghe bozorg rangi ba flourosopy</th>\n",
       "      <th>talasemi</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sen  jens  dard ghafase sineh  feshar khun dar halat esterahat  kolestrol  \\\n",
       "0   63     1                   1                              145        233   \n",
       "1   67     1                   4                              160        286   \n",
       "2   67     1                   4                              120        229   \n",
       "\n",
       "   ghand khun nashta  navar ghalb dar halat esterahat  hadaksar zaraban ghalb  \\\n",
       "0                  1                                2                     150   \n",
       "1                  0                                2                     108   \n",
       "2                  0                                2                     129   \n",
       "\n",
       "   anjin sadri nashi az varzesh  \\\n",
       "0                             0   \n",
       "1                             1   \n",
       "2                             1   \n",
       "\n",
       "   afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat  \\\n",
       "0                                                2.3                   \n",
       "1                                                1.5                   \n",
       "2                                                2.6                   \n",
       "\n",
       "   shibe tamrin dar oje tamrin dar maghtae ST  \\\n",
       "0                                           3   \n",
       "1                                           2   \n",
       "2                                           2   \n",
       "\n",
       "    tedad oroghe bozorg rangi ba flourosopy  talasemi  Outcome  \n",
       "0                                         0         6        0  \n",
       "1                                         3         3        1  \n",
       "2                                         2         7        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Health=Health.rename(columns={'ehtemal voghu bimari ghalbi':'Outcome'})\n",
    "Health.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=Health[['sen','jens','dard ghafase sineh','feshar khun dar halat esterahat','kolestrol','ghand khun nashta','navar ghalb dar halat esterahat','hadaksar zaraban ghalb','anjin sadri nashi az varzesh','afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat','shibe tamrin dar oje tamrin dar maghtae ST','talasemi']]\n",
    "y=Health['Outcome']\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeaturesSelectionGA\n",
    "#This class uses Genetic Algorithm to find out the best features for an input model\n",
    "    #using Distributed Evolutionary Algorithms in Python(DEAP) package. Default toolbox is\n",
    "    #used for GA but it can be changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Roaming\\Python\\Python36\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "from deap import base, creator\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import tools\n",
    "import fitness_function as ff\n",
    "\n",
    "\n",
    "class FeatureSelectionGA:\n",
    "    \"\"\"\n",
    "        FeaturesSelectionGA\n",
    "        This class uses Genetic Algorithm to find out the best features for an input model\n",
    "        using Distributed Evolutionary Algorithms in Python(DEAP) package. Default toolbox is\n",
    "        used for GA but it can be changed accordingly.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,model,x,y,cv_split=5,verbose=0):\n",
    "        \"\"\"\n",
    "            Parameters\n",
    "            -----------\n",
    "            model : scikit-learn supported model, \n",
    "                x :  {array-like}, shape = [n_samples, n_features]\n",
    "                     Training vectors, where n_samples is the number of samples \n",
    "                     and n_features is the number of features.\n",
    " \n",
    "                y  : {array-like}, shape = [n_samples]\n",
    "                     Target Values\n",
    "            cv_split: int\n",
    "                     Number of splits for cross_validation to calculate fitness.\n",
    "            \n",
    "            verbose: 0 or 1\n",
    "        \"\"\"\n",
    "        self.model =  model\n",
    "        self.n_features = x.shape[1]\n",
    "        self.toolbox = None\n",
    "        self.creator = self._create()\n",
    "        self.cv_split = cv_split\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.verbose = verbose\n",
    "        if self.verbose==1:\n",
    "            print(\"Model {} will select best features among {} features using cv_split :{}.\".format(model,x.shape[1],cv_split))\n",
    "            print(\"Shape od train_x: {} and target: {}\".format(x.shape,y.shape))\n",
    "        self.final_fitness = []\n",
    "        self.fitness_in_generation = {}\n",
    "    \t#self.best_ind = None\n",
    "    \n",
    "    def evaluate(self,individual):\n",
    "        fit_obj = ff.FitenessFunction(self.cv_split)\n",
    "        np_ind = np.asarray(individual)\n",
    "        if np.sum(np_ind) == 0:\n",
    "            fitness = 0.0\n",
    "        else:\n",
    "            feature_idx = np.where(np_ind==1)[0]\n",
    "            fitness = fit_obj.calculate_fitness(self.model,self.x[:,feature_idx],self.y)\n",
    "        \n",
    "        if self.verbose == 1:\n",
    "            print(\"Individual: {}  Fitness_score: {} \".format(individual,fitness))\n",
    "            \n",
    "        return fitness,\n",
    "    \n",
    "    \n",
    "    def _create(self):\n",
    "        creator.create(\"FeatureSelect\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FeatureSelect)\n",
    "        return creator\n",
    "    \n",
    "    def create_toolbox(self):\n",
    "        \"\"\" \n",
    "            Custom creation of toolbox.\n",
    "            Parameters\n",
    "            -----------\n",
    "                self\n",
    "            Returns\n",
    "            --------\n",
    "                Initialized toolbox\n",
    "        \"\"\"\n",
    "        \n",
    "        self._init_toolbox()\n",
    "        return toolbox\n",
    "        \n",
    "    def register_toolbox(self,toolbox):\n",
    "        \"\"\" \n",
    "            Register custom created toolbox. Evalute function will be registerd\n",
    "            in this method.\n",
    "            Parameters\n",
    "            -----------\n",
    "                Registered toolbox with crossover,mutate,select tools except evaluate\n",
    "            Returns\n",
    "            --------\n",
    "                self\n",
    "        \"\"\"\n",
    "        toolbox.register(\"evaluate\", self.evaluate)\n",
    "        self.toolbox = toolbox\n",
    "     \n",
    "    \n",
    "    def _init_toolbox(self):\n",
    "        toolbox = base.Toolbox()\n",
    "        toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        # Structure initializers\n",
    "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, self.n_features)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        return toolbox\n",
    "        \n",
    "        \n",
    "    def _default_toolbox(self):\n",
    "        toolbox = self._init_toolbox()\n",
    "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        toolbox.register(\"evaluate\", self.evaluate)\n",
    "        return toolbox\n",
    "    \n",
    "    def get_final_scores(self,pop,fits):\n",
    "        self.final_fitness = list(zip(pop,fits))\n",
    "        \n",
    "    \n",
    "        \n",
    "    def generate(self,n_pop,cxpb = 0.5,mutxpb = 0.2,ngen=5,set_toolbox = False):\n",
    "        \n",
    "        \"\"\" \n",
    "            Generate evolved population\n",
    "            Parameters\n",
    "            -----------\n",
    "                n_pop : {int}\n",
    "                        population size\n",
    "                cxpb  : {float}\n",
    "                        crossover probablity\n",
    "                mutxpb: {float}\n",
    "                        mutation probablity\n",
    "                n_gen : {int}\n",
    "                        number of generations\n",
    "                set_toolbox : {boolean}\n",
    "                              If True then you have to create custom toolbox before calling \n",
    "                              method. If False use default toolbox.\n",
    "            Returns\n",
    "            --------\n",
    "                Fittest population\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.verbose==1:\n",
    "            print(\"Population: {}, crossover_probablity: {}, mutation_probablity: {}, total generations: {}\".format(n_pop,cxpb,mutxpb,ngen))\n",
    "        \n",
    "        if not set_toolbox:\n",
    "            self.toolbox = self._default_toolbox()\n",
    "        else:\n",
    "            raise Exception(\"Please create a toolbox.Use create_toolbox to create and register_toolbox to register. Else set set_toolbox = False to use defualt toolbox\")\n",
    "        pop = self.toolbox.population(n_pop)\n",
    "        CXPB, MUTPB, NGEN = cxpb,mutxpb,ngen\n",
    "\n",
    "        # Evaluate the entire population\n",
    "        print(\"EVOLVING.......\")\n",
    "        fitnesses = list(map(self.toolbox.evaluate, pop))\n",
    "        \n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        for g in range(NGEN):\n",
    "            print(\"-- GENERATION {} --\".format(g+1))\n",
    "            offspring = self.toolbox.select(pop, len(pop))\n",
    "            self.fitness_in_generation[str(g+1)] = max([ind.fitness.values[0] for ind in pop])\n",
    "            # Clone the selected individuals\n",
    "            offspring = list(map(self.toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover and mutation on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < CXPB:\n",
    "                    self.toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            for mutant in offspring:\n",
    "                if random.random() < MUTPB:\n",
    "                    self.toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            weak_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = list(map(self.toolbox.evaluate, weak_ind))\n",
    "            for ind, fit in zip(weak_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "            print(\"Evaluated %i individuals\" % len(weak_ind))\n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            \n",
    "                    # Gather all the fitnesses in one list and print the stats\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "        \n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "        if self.verbose==1:\n",
    "            print(\"  Min %s\" % min(fits))\n",
    "            print(\"  Max %s\" % max(fits))\n",
    "            print(\"  Avg %s\" % mean)\n",
    "            print(\"  Std %s\" % std)\n",
    "    \n",
    "        print(\"-- Only the fittest survives --\")\n",
    "\n",
    "        self.best_ind = tools.selBest(pop, 1)[0]\n",
    "        print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "        self.get_final_scores(pop,fits)\n",
    "        \n",
    "        return pop\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "def iterative_forward_select(X, y, depth=None):\n",
    "    \"\"\"\n",
    "    Performes iterative forward selection on X with targets y.\n",
    "    Currently, only model is linear regression, but this should be\n",
    "    simple to generalize.\n",
    "    Args:\n",
    "    X (pd.DataFrame): DataFrame of predictor variables, dimensions\n",
    "    (n_samples, n_features)\n",
    "    y (pd.Series): Series of target values, dimensions (n_samples, 1)\n",
    "    depth (int): Number of iterations before terminating\n",
    "    Returns:\n",
    "    None\n",
    "    Outputs visualization of each iteration. For each forward\n",
    "    select iteration, the residuals of the previous model are\n",
    "    plotted against each predictor variable. Each plot is\n",
    "    sorted by how predictive the predictor variable is after\n",
    "    already regressing on the previously selected variables.\n",
    "    \"\"\"\n",
    "    if not depth:\n",
    "        \n",
    "        depth = len(X.columns)\n",
    "        current_params = []\n",
    "        iteration = 1\n",
    "        while iteration < depth:\n",
    "            \n",
    "            best_feature = forward_select(X, y, current_params, iteration)\n",
    "            current_params.append(best_feature)\n",
    "            iteration += 1\n",
    "            return None\n",
    "    \n",
    "        def forward_select(X, y, current_params, iteration):\n",
    "            scores = []\n",
    "            columns = np.array([x for x in X.columns if x not in current_params])\n",
    "            \"\"\"\n",
    "            A single round of forward selection. Determines most predictive\n",
    "            variable, and plots how predictive each variable after\n",
    "            regressing on previously selected variables.\n",
    "            Args:\n",
    "            X (pd.DataFrame): DataFrame of predictor variables, dimensions\n",
    "            (n_samples, n_features)\n",
    "            y (pd.Series): Series of target values, dimensions (n_samples, 1)\n",
    "            current_params (list): list of variables already selected for\n",
    "            regression\n",
    "            iteration (int): which iteration through forward selection are\n",
    "            we on\n",
    "            Returns:\n",
    "            Selected Variable (str): Name of variable that minimizes\n",
    "            training error.\n",
    "            Note, this is the best variable after already regressing\n",
    "            on previously selected variables.\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            for column in columns:\n",
    "                model = LinearRegression()\n",
    "                test_params = current_params + [column]\n",
    "                model.fit(X[test_params], y)\n",
    "                score = model.score(X[test_params], y)\n",
    "                scores.append(score)\n",
    "                columns = columns[np.argsort(scores)][::-1]\n",
    "                scores = np.sort(scores)[::-1]\n",
    "                residuals = get_residuals(X, y, current_params)\n",
    "                show_correlations(X, residuals, current_params, iteration, scores, columns)\n",
    "                return columns[0]\n",
    "                    \n",
    "        def get_residuals(X, y, current_params):\n",
    "            \n",
    "            \"\"\"\n",
    "                Calculates residuals for current model\n",
    "                Args:\n",
    "                X (pd.DataFrame): DataFrame of predictor variables, dimensions\n",
    "                (n_samples, n_features)\n",
    "                y (pd.Series): Series of target values, dimensions (n_samples, 1)\n",
    "                current_params (list): list of variables already selected for\n",
    "                regression\n",
    "                iteration (int): which iteration through forward selection are we on\n",
    "                Returns:\n",
    "                residuals (list): list of residuals for each observation\n",
    "            \"\"\"\n",
    "            if len(current_params) == 0:\n",
    "                current_estimate = np.mean(y)\n",
    "                residuals = y - current_estimate\n",
    "            else: \n",
    "                model = LinearRegression()\n",
    "                model.fit(X[current_params], y)\n",
    "                current_estimate = model.predict(X[current_params])\n",
    "                residuals = y - current_estimate\n",
    "                return residuals\n",
    "                def show_correlations(X, residuals, current_params, iteration, scores,\n",
    "                columns):\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Makes plot of correlation between each remaining predictor variable\n",
    "                    and residuals. Each plot is ranked by how predictive the predictor\n",
    "                    variable is after already regressing on the previously selected\n",
    "                    variables.\n",
    "                    Args:\n",
    "                    X (pd.DataFrame): DataFrame of predictor variables, dimensions\n",
    "                    (n_samples, n_features)\n",
    "                    residuals (list): list of residuals for each observation\n",
    "                    current_params (list): list of variables already selected for\n",
    "                    regression\n",
    "                    iteration (int): which iteration through forward selection are\n",
    "                    we on\n",
    "                    scores (list): list of scores representing how well a variable\n",
    "                    improves the previous model\n",
    "                    columns (list): list of predictor variable names\n",
    "                    Returns:\n",
    "                    None\n",
    "                    Outputs files in plots/ directory with filenames being the\n",
    "                    predictor variable names included in the previous model.\n",
    "                    \"\"\"\n",
    "\n",
    "                    n_features = len(columns)\n",
    "                    f, axarr = plt.subplots(n_features, sharex=True, sharey=True,\n",
    "                    figsize=(6, 6 * n_features))\n",
    "                    for i in range(n_features):\n",
    "                        axarr[i].scatter(X[columns[i]], residuals)\n",
    "                        axarr[i].set_ylabel(residuals.name, fontsize=18)\n",
    "                        axarr[i].set_xlabel(columns[i], fontsize=18)\n",
    "                        axarr[i].set_title('R^2: ' + str(scores[i]), fontsize=18)\n",
    "                        plt.tight_layout()\n",
    "                        filename = str(iteration) + '_' + '_'.join(current_params)\n",
    "                        filename = filename.replace(\"/\", \"\")\n",
    "                        filename = filename.replace(\".\", \"\")\n",
    "                        plt.savefig('plots/' + filename)\n",
    "                        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all features: \t(0.8314124293785312,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Roaming\\Python\\Python36\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\Windows 10\\AppData\\Roaming\\Python\\Python36\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tmin     \tmax     \n",
      "0  \t12    \t0.79153\t0.757288\t0.824633\n",
      "1  \t6     \t0.812891\t0.79096 \t0.824633\n",
      "2  \t5     \t0.820198\t0.80452 \t0.824633\n",
      "3  \t7     \t0.819887\t0.78774 \t0.824633\n",
      "4  \t3     \t0.821309\t0.794689\t0.824633\n",
      "5  \t4     \t0.824633\t0.824633\t0.824633\n",
      "6  \t2     \t0.824633\t0.824633\t0.824633\n",
      "7  \t5     \t0.819049\t0.78774 \t0.824633\n",
      "8  \t1     \t0.824633\t0.824633\t0.824633\n",
      "9  \t4     \t0.824633\t0.824633\t0.824633\n",
      "10 \t6     \t0.825202\t0.824633\t0.831469\n",
      "Best Accuracy: \t(0.7572881355932204,)\n",
      "Number of Features in Subset: \t7\n",
      "Individual: \t\t[0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "Feature Subset\t: ['dard ghafase sineh', 'feshar khun dar halat esterahat', 'ghand khun nashta', 'navar ghalb dar halat esterahat', 'afsordegi st nashi az tamrin va varzesh nesbat be halat esterahat', 'shibe tamrin dar oje tamrin dar maghtae ST', ' tedad oroghe bozorg rangi ba flourosopy']\n",
      "\n",
      "\n",
      "creating a new classifier with the result\n",
      "Accuracy with Feature Subset: \t0.7572881355932204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "import sys\n",
    "\n",
    "\n",
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))\n",
    "\n",
    "\n",
    "def getFitness(individual, X, y):\n",
    "    \"\"\"\n",
    "    Feature subset fitness function\n",
    "    \"\"\"\n",
    "\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(individual)) if individual[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "        return (avg(cross_val_score(clf, X_subset, y, cv=5)),)\n",
    "    else:\n",
    "        return(0,)\n",
    "\n",
    "\n",
    "def geneticAlgorithm(X, y, n_population, n_generation):\n",
    "    \"\"\"\n",
    "    Deap global variables\n",
    "    Initialize variables to use eaSimple\n",
    "    \"\"\"\n",
    "    # create individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    # create toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat,\n",
    "                     creator.Individual, toolbox.attr_bool, len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list,\n",
    "                     toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", getFitness, X=X, y=y)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # initialize parameters\n",
    "    pop = toolbox.population(n=n_population)\n",
    "    hof = tools.HallOfFame(n_population * n_generation)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # genetic algorithm\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.2, mutpb=0.2,\n",
    "                                   ngen=n_generation, stats=stats, halloffame=hof,\n",
    "                                   verbose=True)\n",
    "\n",
    "    # return hall of fame\n",
    "    return hof\n",
    "\n",
    "\n",
    "def bestIndividual(hof, X, y):\n",
    "    \"\"\"\n",
    "    Get the best individual\n",
    "    \"\"\"\n",
    "    maxAccurcy = 0.0\n",
    "    for individual in hof:\n",
    "        #if(individual.fitness.values > maxAccurcy):\n",
    "            maxAccurcy = individual.fitness.values\n",
    "            _individual = individual\n",
    "\n",
    "    _individualHeader = [list(X)[i] for i in range(\n",
    "        len(_individual)) if _individual[i] == 1]\n",
    "    return _individual.fitness.values, _individual, _individualHeader\n",
    "\n",
    "\n",
    "def getArguments():\n",
    "    \"\"\"\n",
    "    Get argumments from command-line\n",
    "    If pass only dataframe path, pop and gen will be default\n",
    "    \"\"\"\n",
    "    dfPath = sys.argv[1]\n",
    "    if(len(sys.argv) == 4):\n",
    "        pop = int(sys.argv[2])\n",
    "        gen = int(sys.argv[3])\n",
    "    else:\n",
    "        pop = 12\n",
    "        gen = 10\n",
    "    return dfPath, pop, gen\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # get dataframe path, population number and generation number from command-line argument\n",
    "    dataframePath, n_pop, n_gen = getArguments()\n",
    "    # read dataframe from csv\n",
    "    df = pd.read_excel('Health.xlsx')\n",
    "\n",
    "    # encode labels column to numbers\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.iloc[:, -1])\n",
    "    y = le.transform(df.iloc[:, -1])\n",
    "    X = df.iloc[:, :-1]\n",
    "\n",
    "    # get accuracy with all features\n",
    "    individual = [1 for i in range(len(X.columns))]\n",
    "    print(\"Accuracy with all features: \\t\" +\n",
    "          str(getFitness(individual, X, y)) + \"\\n\")\n",
    "\n",
    "    # apply genetic algorithm\n",
    "    hof = geneticAlgorithm(X, y, n_pop, n_gen)\n",
    "\n",
    "    # select the best individual\n",
    "    accuracy, individual, header = bestIndividual(hof, X, y)\n",
    "    print('Best Accuracy: \\t' + str(accuracy))\n",
    "    print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "    print('Individual: \\t\\t' + str(individual))\n",
    "    print('Feature Subset\\t: ' + str(header))\n",
    "\n",
    "    print('\\n\\ncreating a new classifier with the result')\n",
    "\n",
    "    # read dataframe from csv one more time\n",
    "    df = pd.read_excel('Health.xlsx')\n",
    "\n",
    "    # with feature subset\n",
    "    X = df[header]\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"Accuracy with Feature Subset: \\t\" + str(avg(scores)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 7.6850 - acc: 0.5232\n",
      "Epoch 2/5\n",
      "237/237 [==============================] - 0s 114us/step - loss: 7.6850 - acc: 0.5232\n",
      "Epoch 3/5\n",
      "237/237 [==============================] - 0s 112us/step - loss: 7.6850 - acc: 0.5232\n",
      "Epoch 4/5\n",
      "237/237 [==============================] - 0s 127us/step - loss: 7.6850 - acc: 0.5232\n",
      "Epoch 5/5\n",
      "237/237 [==============================] - 0s 101us/step - loss: 7.6850 - acc: 0.5232\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Test Loss:  6.447238190968831 , Test Accuracy:  0.599999992052714\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, models\n",
    "\n",
    "diabetic = pd.read_excel('Health.xlsx')\n",
    "X=Health[['sen','jens','dard ghafase sineh','feshar khun dar halat esterahat','kolestrol',\n",
    "          'ghand khun nashta','navar ghalb dar halat esterahat','hadaksar zaraban ghalb']]\n",
    "y=Health['Outcome']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(1, input_shape=[8], activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test Loss: ', test_loss, ', Test Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
